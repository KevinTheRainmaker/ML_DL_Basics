{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "18_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBve5xZBDEs9Vp0Bet+g9R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinTheRainmaker/ML_DL_Basics/blob/master/HonGong_ML_DL/18_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 순차 데이터와 순환 신경망\n",
        "\n",
        "### **키워드:** 순차 데이터, 순환 신경망, 셀, 은닉 상태 \n",
        "\n",
        "순차 데이터의 특징을 알고 순환 신경망의 개념에 대해 배워보자"
      ],
      "metadata": {
        "id": "5YZVudFSHmeW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LOq80fluHY1f"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 순차 데이터"
      ],
      "metadata": {
        "id": "qVedRy7eJdb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "순차 데이터(sequential data)는 텍스트나 시계열 데이터(time series data)와 같이 순서에 의미가 있는, 달리 말하면 순서가 달라지면 의미가 달라지거나 이해하기 어려워지는 데이터를 지칭한다.\n",
        "\n",
        "대부분의 데이터는 순서가 크게 상관이 없었고, 오히려 랜덤하게 셔플하는 편이 더 좋은 결과를 내기도 했다. 하지만 시계열 데이터의 경우 순서를 그대로 사용해야만 한다."
      ],
      "metadata": {
        "id": "aL25GSRcJfMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전의 샘플을 다음 샘플 계산에 이용하지 않는 다른 신경망과 달리, 순차 데이터를 다룰 때는 이전에 입력한 데이터를 기억하는 메모리 기능이 필요하다.\n",
        "\n",
        "입력 데이터가 재사용되지 않고 데이터의 흐름이 앞으로만 전달되는 신경망을 피드포워드 신경망(feedforward neural network)이라고 하며, 이와 상반되게 데이터를 재사용하며 데이터가 신경망 층을 순환하는 것을 순환 신경망(recurrent neural network)이라고 한다."
      ],
      "metadata": {
        "id": "0EY10v0qMo0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 순환 신경망"
      ],
      "metadata": {
        "id": "MfzwGDecNgNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 설명했듯이, 순환 신경망은 데이터가 지속적으로 신경망을 순환하며 재사용된다.\n",
        "\n",
        "앞서 학습했던 완전 연결 신경망에 이전 데이터 처리 흐름을 순환하는 고리 하나만 추가해주면 되기에 구현 또한 간단한 편이다. 순환 신경망은 직전의 데이터에 의한 아웃풋을 되먹임으로 사용하기 때문에 다음 아웃풋에는 더 앞선 데이터보다는 직전 데이터에 대한 정보가 더 많이 들어가 있을 것이다. 이렇게 샘플을 처리하는 하나의 단계를 타임스텝(timestep)이라고 하며, 타임스텝이 오래될수록 순환되는 정보는 희미해진다."
      ],
      "metadata": {
        "id": "2a_EJ5Y8NiD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "순환 신경망에서는 특별히 층을 셀(cell)이라고 부른다. 실제로는 한 셀에 여러 개의 뉴런이 있지만 완전 연결 신경망과 달리 뉴런을 전부 표현하지 않고 하나의 셀을 층이라고 부르는 것이다. 이러한 셀의 출력은 은닉 상태(hidden state)라고 부른다. 이러한 은닉 상태가 매 타임스텝마다 재사용 된다."
      ],
      "metadata": {
        "id": "CIIZ-DloO8hU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적으로 은닉층의 활성화 함수로는 하이퍼볼릭 탄젠트(hyperbolic tangent) 함수인 tanh가 많이 사용된다. 시그모이드와 비슷하게 S자 형태를 가졌으나 tanh는 -1\\~1의 범위를 가진다. (시그모이드는 0~1)"
      ],
      "metadata": {
        "id": "cx2py5KNQqMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 셀의 가중치"
      ],
      "metadata": {
        "id": "WiZVH0dCTkVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 잘 이해하는 방법 중 하나는 가중치를 계산해보는 것이다. 순환 신경망의 셀에서 필요한 가중치의 크기를 계산해보자. \n",
        "\n",
        "순환층에 입력되는 특성이 4개이고 각 순환층의 뉴런이 3개라고 가정하자. 입력층과 순환층은 완전 연결을 이루고 있기 때문에 입력에 곱해지는 가중치 $w_x$의 크기는 특성 개수 4 * 뉴런 수 3 = 12개가 된다. \n",
        "\n",
        "다음으로 순환층에서 다음 타임스텝에 재사용되는 은닉 상태를 위한 가중치 $w_b$의 크기를 생각해보자. 순환층에 있는 첫 번째 뉴런의 은닉 상태가 타임스텝에 재사용될 때 3개 뉴런 모두에 전달된다. 두 번째와 세 번째도 마찬가지이다. 따라서 $w_b$의 크기는 뉴런 수 3^2 = 9개이다."
      ],
      "metadata": {
        "id": "ZnyBjc8fTm0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번엔 모델 파라미터 개수를 구해보자. 이는 가중치에 절편을 더하면 된다. 순환 신경망에는 각 뉴런마다 하나의 절편이 있으므로 총 12 + 9 + 3 = 24개의 모델 파라미터를 가지게 된다.\n",
        "\n",
        "$모델\\ 파라미터\\ 수=w_x + w_b + 절편 + = 12 + 9 + 3 = 24$"
      ],
      "metadata": {
        "id": "mJ9vWWtuKxSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 순환층의 입출력"
      ],
      "metadata": {
        "id": "1oRlpdaTLn2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "순환층은 일반적으로 샘플마다 2개의 차원을 가진다. 보통 하나의 샘플을 하나의 시퀀스(sequence)라고 한다. 시퀀스 안에는 여러 개의 아이템이 들어있는데, 여기서의 시퀀스의 길이가 바로 타임스텝의 길이가 된다.\n",
        "\n",
        "이런 입력이 순환층을 통과하게 되면 두 번째, 세 번째 차원이 사라지고 순환층의 뉴런 개수만큼 출력된다. 하나의 샘플은 시퀀스 길이와 타임스탬프 수로 이루어진 2차원 배열이다. 이 샘플이 순환층을 통과할 때 실제로는 마지막 타임스텝에서만 출력을 내보내기 때문에 2차원의 배열은 1차원으로 바뀌게 되며, 이때의 크기는 순환층의 뉴런 개수에 의해 결정된다. 시퀀스를 모두 읽어 마지막 은닉 상태에 압축하여 출력하는 것으로 이해해도 무방하다.\n",
        "\n",
        "다만 순환층이 여러 개인 경우 마지막 순환층을 제외하고는 모든 타임스텝의 은닉 상태를 출력하여 다음 순환층에 2차원 입력으로 들어갈 수 있도록 한다."
      ],
      "metadata": {
        "id": "mzLRxS1xLvs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "순환 신경망도 마지막에는 밀집층을 두어 클래스를 분류하는데, 다중 분류일 경우 출력층에 클래스 개수만큼 뉴런을 두고 소프트맥스를, 이진 분류인 경우 하나의 뉴런을 두고 시그모이드를 사용한다.\n",
        "\n",
        "마지막 셀의 출력이 1차원이기 때문에 CNN과 달리 Flatten으로 펼쳐주지 않아도 된다."
      ],
      "metadata": {
        "id": "hNNVZN2nAfDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 순환 신경망으로 IMDB 리뷰 분류하기\n",
        "\n",
        "### **키워드:** 말뭉치, 토큰, 원-핫 인코딩, 단어 임베딩\n",
        "\n",
        "텐서플로우를 사용해 순환 신경망을 만들어 영화 리뷰 데이터셋에 적용해서 리뷰를 긍정과 부정으로 분류해보자."
      ],
      "metadata": {
        "id": "X9lUkGkuA5Gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋"
      ],
      "metadata": {
        "id": "ODhLDGXSBTCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDB 리뷰 데이터셋은 유명 인터넷 영화 데이터베이스인 [imdb.com](https://www.imdb.com/)에서 수집한 리뷰를 감상평에 따라 긍정과 부정으로 분류해 놓은 데이터셋이다. 자연어처리에서 많이 사용되는 데이터셋 중 하나로, 말뭉치(corpus)라고도 불린다."
      ],
      "metadata": {
        "id": "NqxK5qBQBZd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제 IMDB 리뷰 데이터셋은 영어로 된 문장이지만 텐서플로우에는 이미 토큰화된 데이터가 포함되어 있다. 여기에서는 전체 데이터셋에서 가장 자주 등장하는 500 단어만을 사용해보도록 하겠다."
      ],
      "metadata": {
        "id": "5zR7DL5BBzre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=500)"
      ],
      "metadata": {
        "id": "AqR2NdDUJPld"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrIbk0oHCeT7",
        "outputId": "dc533ed9-8ebd-424f-b2e6-e64e4cefd257"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,) (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰 데이터는 길이가 제각각이기 때문에 고정 크기의 2차원 배열에 담기보다는 리뷰마다 별도의 파이썬 리스트로 담아야 메모리를 효율적으로 사용할 수 있다. 즉 위의 데이터는 개별 리뷰를 담은 파이썬 리스트 객체로 이루어진 넘파이 배열이다."
      ],
      "metadata": {
        "id": "X5gGtzHdCoME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train[0]))\n",
        "print(len(X_train[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWIDT58pCjoo",
        "outputId": "176f52c7-5a77-40f6-ec82-f6835b12a5b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218\n",
            "189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5KM0o0gDCVt",
        "outputId": "ebdd442f-cb48-49a8-9b46-0cb0c24fd92e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "500개 최빈 데이터 외의 데이터는 2로 표시되어있다. 이런 토큰을 OOV 토큰(Out of Vacabulary Token)이라고 한다."
      ],
      "metadata": {
        "id": "cYHWEPlpDWO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "qQt3A2KjDnGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "lengths = np.array([len(x) for x in X_train])\n",
        "print(np.mean(lengths), np.median(lengths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVynezpZDLSS",
        "outputId": "a41ebb4f-6995-4010-85d8-73738b0f8745"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239.00925 178.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(lengths)\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "0JUgnA-hEAmK",
        "outputId": "3f9c7253-d69e-4eed-952d-1b0f10880001"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "리뷰들의 길이가 제각각이다. 이러한 다양한 길이의 텍스트 데이터의 길이를 맞춰주기 위해 패딩(padding)을 이용한다.\n",
        "\n",
        "`pad_sequence()`를 사용하면 시퀀스 데이터의 길이를 maxlen에 맞춰 그보다 긴 경우 잘라내고, 짧은 경우 0으로 채운다.\n",
        "\n",
        "여기서는 100 정도를 사용하겠다."
      ],
      "metadata": {
        "id": "6XnUYqWpErS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_seq = pad_sequences(X_train, maxlen=100)"
      ],
      "metadata": {
        "id": "4DxtWwpTENTs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otdi0FXdFA8r",
        "outputId": "6bfbd57b-f21c-4e8f-b5b3-bd147b162e79"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnGOUpOuFN7A",
        "outputId": "8eac2805-fc3e-4cb7-bb69-061cfa68b608"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2\n",
            "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
            "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
            "   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91\n",
            "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
            "   6   2  46   7  14  20  10  10 470 158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞쪽에 0이 채워져있다. 자르거나 채우는 방향은 pad_sequence()의 padding과 truncating 매개변수로 조절할 수 있다."
      ],
      "metadata": {
        "id": "dL5yCAzDFtX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_seq = pad_sequences(X_val, maxlen=100)"
      ],
      "metadata": {
        "id": "tzJnB_ipJDZZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 순환 신경망 만들기"
      ],
      "metadata": {
        "id": "WMCz2GQCHP3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스는 여러 종류의 순환층 클래스를 제공한다. 그중 가장 간단한 것은 SimpleRNN 클래스이다."
      ],
      "metadata": {
        "id": "kaw3aiLsHTMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.SimpleRNN(8, input_shape=(100, 500))) # 토큰에 대응되는 정수값을 원핫 인코딩으로 만들기 위한 500 길이의 배열\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "7ZhCD7krFrIl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원-핫 인코딩\n",
        "train_oh = keras.utils.to_categorical(train_seq)\n",
        "print(train_oh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8exq2dNHzJi",
        "outputId": "28b34ab5-827e-420e-82e0-85bde549732d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 100, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_oh = keras.utils.to_categorical(val_seq)"
      ],
      "metadata": {
        "id": "KeCUCqhcIZR-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU13X2wOI9hA",
        "outputId": "08735bf9-f699-417d-aff1-2352d373a798"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 8)                 4072      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,081\n",
            "Trainable params: 4,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 순환 신경망 훈련하기"
      ],
      "metadata": {
        "id": "vIPpACRWJb0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(train_oh, y_train, epochs=100, batch_size=64,\n",
        "                    validation_data=(val_oh, y_val),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXeUSNZiJacR",
        "outputId": "40065db3-bb64-4a98-e41a-b9d2db14f47e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "313/313 [==============================] - 16s 47ms/step - loss: 0.6990 - accuracy: 0.5051 - val_loss: 0.6943 - val_accuracy: 0.5140\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.6937 - accuracy: 0.5095 - val_loss: 0.6925 - val_accuracy: 0.5182\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.6916 - accuracy: 0.5224 - val_loss: 0.6912 - val_accuracy: 0.5244\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.6899 - accuracy: 0.5314 - val_loss: 0.6902 - val_accuracy: 0.5338\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.6884 - accuracy: 0.5414 - val_loss: 0.6892 - val_accuracy: 0.5408\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.6869 - accuracy: 0.5497 - val_loss: 0.6883 - val_accuracy: 0.5450\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.6854 - accuracy: 0.5542 - val_loss: 0.6872 - val_accuracy: 0.5450\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.6839 - accuracy: 0.5600 - val_loss: 0.6862 - val_accuracy: 0.5466\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.6825 - accuracy: 0.5652 - val_loss: 0.6854 - val_accuracy: 0.5484\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.6811 - accuracy: 0.5691 - val_loss: 0.6849 - val_accuracy: 0.5504\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.6796 - accuracy: 0.5706 - val_loss: 0.6842 - val_accuracy: 0.5504\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.6782 - accuracy: 0.5748 - val_loss: 0.6836 - val_accuracy: 0.5554\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 0.6768 - accuracy: 0.5778 - val_loss: 0.6830 - val_accuracy: 0.5550\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.6753 - accuracy: 0.5788 - val_loss: 0.6822 - val_accuracy: 0.5560\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.6739 - accuracy: 0.5824 - val_loss: 0.6815 - val_accuracy: 0.5562\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.6725 - accuracy: 0.5845 - val_loss: 0.6812 - val_accuracy: 0.5538\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.6711 - accuracy: 0.5865 - val_loss: 0.6808 - val_accuracy: 0.5562\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 12s 40ms/step - loss: 0.6697 - accuracy: 0.5892 - val_loss: 0.6803 - val_accuracy: 0.5580\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.6682 - accuracy: 0.5912 - val_loss: 0.6797 - val_accuracy: 0.5552\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.6668 - accuracy: 0.5925 - val_loss: 0.6794 - val_accuracy: 0.5554\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.6654 - accuracy: 0.5950 - val_loss: 0.6787 - val_accuracy: 0.5580\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.6640 - accuracy: 0.5987 - val_loss: 0.6785 - val_accuracy: 0.5566\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.6626 - accuracy: 0.5983 - val_loss: 0.6780 - val_accuracy: 0.5576\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.6611 - accuracy: 0.6018 - val_loss: 0.6777 - val_accuracy: 0.5608\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.6596 - accuracy: 0.6028 - val_loss: 0.6770 - val_accuracy: 0.5612\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.6581 - accuracy: 0.6079 - val_loss: 0.6773 - val_accuracy: 0.5610\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.6567 - accuracy: 0.6074 - val_loss: 0.6762 - val_accuracy: 0.5596\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.6552 - accuracy: 0.6102 - val_loss: 0.6755 - val_accuracy: 0.5610\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 14s 43ms/step - loss: 0.6537 - accuracy: 0.6118 - val_loss: 0.6755 - val_accuracy: 0.5616\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.6521 - accuracy: 0.6140 - val_loss: 0.6756 - val_accuracy: 0.5618\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.6505 - accuracy: 0.6178 - val_loss: 0.6744 - val_accuracy: 0.5662\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.6489 - accuracy: 0.6197 - val_loss: 0.6746 - val_accuracy: 0.5666\n",
            "Epoch 33/100\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.6471 - accuracy: 0.6220 - val_loss: 0.6740 - val_accuracy: 0.5658\n",
            "Epoch 34/100\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 0.6449 - accuracy: 0.6262 - val_loss: 0.6721 - val_accuracy: 0.5676\n",
            "Epoch 35/100\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.6399 - accuracy: 0.6332 - val_loss: 0.6629 - val_accuracy: 0.5954\n",
            "Epoch 36/100\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.6272 - accuracy: 0.6537 - val_loss: 0.6482 - val_accuracy: 0.6198\n",
            "Epoch 37/100\n",
            "313/313 [==============================] - 14s 43ms/step - loss: 0.6115 - accuracy: 0.6761 - val_loss: 0.6314 - val_accuracy: 0.6508\n",
            "Epoch 38/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.5909 - accuracy: 0.6960 - val_loss: 0.6124 - val_accuracy: 0.6720\n",
            "Epoch 39/100\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.5673 - accuracy: 0.7182 - val_loss: 0.5901 - val_accuracy: 0.6950\n",
            "Epoch 40/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.5418 - accuracy: 0.7400 - val_loss: 0.5668 - val_accuracy: 0.7178\n",
            "Epoch 41/100\n",
            "313/313 [==============================] - 15s 46ms/step - loss: 0.5185 - accuracy: 0.7546 - val_loss: 0.5456 - val_accuracy: 0.7268\n",
            "Epoch 42/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.4979 - accuracy: 0.7667 - val_loss: 0.5293 - val_accuracy: 0.7426\n",
            "Epoch 43/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.4814 - accuracy: 0.7773 - val_loss: 0.5140 - val_accuracy: 0.7528\n",
            "Epoch 44/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.4663 - accuracy: 0.7881 - val_loss: 0.5035 - val_accuracy: 0.7570\n",
            "Epoch 45/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.4551 - accuracy: 0.7944 - val_loss: 0.4893 - val_accuracy: 0.7684\n",
            "Epoch 46/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4454 - accuracy: 0.7993 - val_loss: 0.4820 - val_accuracy: 0.7738\n",
            "Epoch 47/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.4376 - accuracy: 0.8038 - val_loss: 0.4760 - val_accuracy: 0.7808\n",
            "Epoch 48/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4306 - accuracy: 0.8069 - val_loss: 0.4711 - val_accuracy: 0.7828\n",
            "Epoch 49/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.4241 - accuracy: 0.8109 - val_loss: 0.4675 - val_accuracy: 0.7858\n",
            "Epoch 50/100\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.4198 - accuracy: 0.8120 - val_loss: 0.4653 - val_accuracy: 0.7812\n",
            "Epoch 51/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.4158 - accuracy: 0.8153 - val_loss: 0.4670 - val_accuracy: 0.7792\n",
            "Epoch 52/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.4123 - accuracy: 0.8165 - val_loss: 0.4611 - val_accuracy: 0.7876\n",
            "Epoch 53/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.4089 - accuracy: 0.8184 - val_loss: 0.4576 - val_accuracy: 0.7914\n",
            "Epoch 54/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.4061 - accuracy: 0.8204 - val_loss: 0.4573 - val_accuracy: 0.7888\n",
            "Epoch 55/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.4037 - accuracy: 0.8213 - val_loss: 0.4550 - val_accuracy: 0.7910\n",
            "Epoch 56/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.4011 - accuracy: 0.8232 - val_loss: 0.4545 - val_accuracy: 0.7920\n",
            "Epoch 57/100\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.3992 - accuracy: 0.8249 - val_loss: 0.4545 - val_accuracy: 0.7914\n",
            "Epoch 58/100\n",
            "313/313 [==============================] - 13s 42ms/step - loss: 0.3970 - accuracy: 0.8249 - val_loss: 0.4545 - val_accuracy: 0.7924\n",
            "Epoch 59/100\n",
            "313/313 [==============================] - 14s 43ms/step - loss: 0.3956 - accuracy: 0.8270 - val_loss: 0.4570 - val_accuracy: 0.7868\n",
            "Epoch 60/100\n",
            "313/313 [==============================] - 14s 43ms/step - loss: 0.3938 - accuracy: 0.8274 - val_loss: 0.4548 - val_accuracy: 0.7902\n",
            "Epoch 61/100\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.3929 - accuracy: 0.8279 - val_loss: 0.4578 - val_accuracy: 0.7878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "51vbZbDBKnmz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}