{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16_DNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNA0u+k9MPtFDLz3fSddZC0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinTheRainmaker/ML_DL_Basics/blob/master/HonGong_ML_DL/16_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 심층 신경망\n",
        "\n",
        "### **키워드:** 심층 신경망, ReLU 함수, 옵티마이저\n",
        "\n",
        "케라스 인공 신경망에 은닉층을 추가하여 심층 신경망을 만들고 분류 과제를 수행해보자."
      ],
      "metadata": {
        "id": "looHiJxESZk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D_XFH1mfSRKE"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋"
      ],
      "metadata": {
        "id": "C3TkhJm1eda6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_scaled = X_train / 255.0\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "\n",
        "train_scaled, val_scaled, y_train, y_val = train_test_split(train_scaled, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28QWmYDoefKW",
        "outputId": "9ea7e5ac-77b8-4e2d-c38d-3c60c0b4a649"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 은닉층"
      ],
      "metadata": {
        "id": "uqUXQ1BxXb-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "은닉층(hidden layer)란 입력층과 출력층 사이 존재하는 모든 층을 지칭하는 용어이다. 은닉층에 적용되는 활성화 함수는 출력층과 달리 다소 자유로운 편으로, 시그모이드 혹은 렐루(ReLU) 함수가 주로 이용된다."
      ],
      "metadata": {
        "id": "D9JUT8DQXdxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "은닉층에서 활성화 함수를 사용함으로써 선형 계산을 비선형 계산으로 틀어 계산의 복잡도와 정확도를 높인다."
      ],
      "metadata": {
        "id": "avcDl-Q8YBzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)) # 은닉층\n",
        "dense2 = keras.layers.Dense(10, activation='softmax') # 출력층"
      ],
      "metadata": {
        "id": "rw9Nfw1EXaY2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dense1`은 은닉층으로 100개의 뉴런을 가진 밀집층이다. 활성화 함수로 sigmoid를 지정했으며 `input_shape` 매개변수에서 입력의 크기를 (784,)로 지정했다.\n",
        "\n",
        "은닉층의 뉴런 개수를 정하는 기준은 출쳑층의 뉴런보다 많아야 한다는 점 외에는 특별히 존재하지 않으며, 경험적으로 정해지곤 한다."
      ],
      "metadata": {
        "id": "FCSSOiggYj1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dense1`는 출력층으로, 10개의 뉴런을 가지고 클래스를 분류한다. 다중 확률 값 중 최대치를 출력하기 위해 활성화 함수는 softmax로 설정하였다."
      ],
      "metadata": {
        "id": "cM7aZdRNZAlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 심층 신경망 만들기"
      ],
      "metadata": {
        "id": "kkfgK5Q0ZNLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 만든 `dense1`과 `dense2` 객체를 Sequential 클래스에 추가하여 심층 신경망(Deep Neural Network, DNN)을 만들어보자."
      ],
      "metadata": {
        "id": "OzZEp5EYZorZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([dense1, dense2])"
      ],
      "metadata": {
        "id": "3wJOhH2ZYjIi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "심층 신경망을 만들 때는 각 레이어를 순서대로 배치해야한다."
      ],
      "metadata": {
        "id": "BG0OcFsMZ5Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yzWxihLZ3uL",
        "outputId": "4bae29f2-a55a-4ca8-fb45-81cc9ad8eabf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "맨 첫 줄에 모델의 이름(sequential)이 나와있다. \n",
        "\n",
        "층마다 층 이름, 클래스, 출력 크기, 모델 파라미터 개수가 차례로 출력된다. 층을 만들 때 name 매개변수로 이름을 지정할 수 있는데, 따로 지정하지 않을 경우 자동으로 dense라는 이름이 붙는다.\n",
        "\n",
        "출력 크기 (None, 100)의 앞쪽 None은 샘플의 개수를 나타내는데, None으로 나타나는 이유는 샘플의 개수가 정의되어 있지 않기 때문이다. 케라스 모델의 `fit()` 메서드가 기본적으로 32개의 미니배치를 사용하는 미니배치 경사하강법을 채택하는데, 이때의 미니배치의 사이즈는 `fit()` 메서드의 `batch_size` 매개변수로 바꿀 수 있다. 따라서 어떤 배치 크기에도 유연하게 대응할 수 있도록 None으로 설정한다. 이렇게 신경망 층에 입력되거나 출력되는 배열의 첫 번째 차원을 배치 차원(batch dimension)이라고 부른다."
      ],
      "metadata": {
        "id": "prKZeZkeaUKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "은닉층 또한 Dense층으로 설정했으므로 784 * 100 조합에 대한 가중치가 있고, 각 은닉층 뉴런에는 상응하는 절편이 있으며, 마지막 출력층에 대해서도 Dense층을 이루기 때문에 (784 \\* 100 + 100) + (100 \\* 10 + 10) = 79,510개의 훈련 파라미터(Trainable parmas)가 존재하게 된다.\n",
        "\n",
        "아래의 Non-trainable params는 경사 하강법으로 훈련되지 않는 파라미터를 가진 층의 파라미터 개수이다."
      ],
      "metadata": {
        "id": "rRbaRZ16bvDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음과 같은 방식으로 레이어의 정의와 신경망 구축을 동시에 진행할 수도 있다.\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
        "                          keras.layers.Dense(10, activation='softmax', name='output')\n",
        "], name='Fashion_MNIST_Model')"
      ],
      "metadata": {
        "id": "NVBt9dxRaHsR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 이름은 한글이어도 상관없으나, 층의 이름은 반드시 영문이어야한다."
      ],
      "metadata": {
        "id": "5QH16_p6dfAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWiNL_tHdZOc",
        "outputId": "6c95bdf7-7c81-4236-a8c2-efa37cfa40fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Fashion_MNIST_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "층이 많아질 경우 위와 같은 방식으로 하기 불편해질 수 있는데, 이럴 경우 `add()` 메서드가 사용되곤 한다."
      ],
      "metadata": {
        "id": "9h2LL5GLdqXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(name='Fashion_MNIST_Model')\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax', name='output'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieXmkYAfdbWf",
        "outputId": "f7db92d9-6f84-47e1-91db-3b85e574adc8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Fashion_MNIST_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 앞서 만든 모델을 훈련해보자."
      ],
      "metadata": {
        "id": "y265UCBXeKPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5QCi0b0d8Hf",
        "outputId": "797eeee5-4f5c-49a2-d192-cea5b667a27f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 6s 3ms/step - loss: 0.5605 - accuracy: 0.8082\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4068 - accuracy: 0.8531\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3726 - accuracy: 0.8648\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3492 - accuracy: 0.8730\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3322 - accuracy: 0.8792\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f694c880650>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "추가된 층이 성능을 향상시켰다. 층의 몇 개가 추가되는 사용법이 동일한 것은 케라스 API의 장점 중 하나이다."
      ],
      "metadata": {
        "id": "mNiR7aiCexw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vLEruYTjernT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}