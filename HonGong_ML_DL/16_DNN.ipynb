{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16_DNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWg9hZliciIeV0vAZ/sc3e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinTheRainmaker/ML_DL_Basics/blob/master/HonGong_ML_DL/16_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 심층 신경망\n",
        "\n",
        "### **키워드:** 심층 신경망, ReLU 함수, 옵티마이저\n",
        "\n",
        "케라스 인공 신경망에 은닉층을 추가하여 심층 신경망을 만들고 분류 과제를 수행해보자."
      ],
      "metadata": {
        "id": "looHiJxESZk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D_XFH1mfSRKE"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋"
      ],
      "metadata": {
        "id": "C3TkhJm1eda6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_scaled = X_train / 255.0\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "\n",
        "train_scaled, val_scaled, y_train, y_val = train_test_split(train_scaled, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "28QWmYDoefKW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 은닉층"
      ],
      "metadata": {
        "id": "uqUXQ1BxXb-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "은닉층(hidden layer)란 입력층과 출력층 사이 존재하는 모든 층을 지칭하는 용어이다. 은닉층에 적용되는 활성화 함수는 출력층과 달리 다소 자유로운 편으로, 시그모이드 혹은 렐루(ReLU) 함수가 주로 이용된다."
      ],
      "metadata": {
        "id": "D9JUT8DQXdxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "은닉층에서 활성화 함수를 사용함으로써 선형 계산을 비선형 계산으로 틀어 계산의 복잡도와 정확도를 높인다."
      ],
      "metadata": {
        "id": "avcDl-Q8YBzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)) # 은닉층\n",
        "dense2 = keras.layers.Dense(10, activation='softmax') # 출력층"
      ],
      "metadata": {
        "id": "rw9Nfw1EXaY2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dense1`은 은닉층으로 100개의 뉴런을 가진 밀집층이다. 활성화 함수로 sigmoid를 지정했으며 `input_shape` 매개변수에서 입력의 크기를 (784,)로 지정했다.\n",
        "\n",
        "은닉층의 뉴런 개수를 정하는 기준은 출쳑층의 뉴런보다 많아야 한다는 점 외에는 특별히 존재하지 않으며, 경험적으로 정해지곤 한다."
      ],
      "metadata": {
        "id": "FCSSOiggYj1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dense1`는 출력층으로, 10개의 뉴런을 가지고 클래스를 분류한다. 다중 확률 값 중 최대치를 출력하기 위해 활성화 함수는 softmax로 설정하였다."
      ],
      "metadata": {
        "id": "cM7aZdRNZAlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 심층 신경망 만들기"
      ],
      "metadata": {
        "id": "kkfgK5Q0ZNLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 만든 `dense1`과 `dense2` 객체를 Sequential 클래스에 추가하여 심층 신경망(Deep Neural Network, DNN)을 만들어보자."
      ],
      "metadata": {
        "id": "OzZEp5EYZorZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([dense1, dense2])"
      ],
      "metadata": {
        "id": "3wJOhH2ZYjIi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "심층 신경망을 만들 때는 각 레이어를 순서대로 배치해야한다."
      ],
      "metadata": {
        "id": "BG0OcFsMZ5Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yzWxihLZ3uL",
        "outputId": "4bae29f2-a55a-4ca8-fb45-81cc9ad8eabf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "맨 첫 줄에 모델의 이름(sequential)이 나와있다. \n",
        "\n",
        "층마다 층 이름, 클래스, 출력 크기, 모델 파라미터 개수가 차례로 출력된다. 층을 만들 때 name 매개변수로 이름을 지정할 수 있는데, 따로 지정하지 않을 경우 자동으로 dense라는 이름이 붙는다.\n",
        "\n",
        "출력 크기 (None, 100)의 앞쪽 None은 샘플의 개수를 나타내는데, None으로 나타나는 이유는 샘플의 개수가 정의되어 있지 않기 때문이다. 케라스 모델의 `fit()` 메서드가 기본적으로 32개의 미니배치를 사용하는 미니배치 경사하강법을 채택하는데, 이때의 미니배치의 사이즈는 `fit()` 메서드의 `batch_size` 매개변수로 바꿀 수 있다. 따라서 어떤 배치 크기에도 유연하게 대응할 수 있도록 None으로 설정한다. 이렇게 신경망 층에 입력되거나 출력되는 배열의 첫 번째 차원을 배치 차원(batch dimension)이라고 부른다."
      ],
      "metadata": {
        "id": "prKZeZkeaUKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "은닉층 또한 Dense층으로 설정했으므로 784 * 100 조합에 대한 가중치가 있고, 각 은닉층 뉴런에는 상응하는 절편이 있으며, 마지막 출력층에 대해서도 Dense층을 이루기 때문에 (784 \\* 100 + 100) + (100 \\* 10 + 10) = 79,510개의 훈련 파라미터(Trainable parmas)가 존재하게 된다.\n",
        "\n",
        "아래의 Non-trainable params는 경사 하강법으로 훈련되지 않는 파라미터를 가진 층의 파라미터 개수이다."
      ],
      "metadata": {
        "id": "rRbaRZ16bvDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음과 같은 방식으로 레이어의 정의와 신경망 구축을 동시에 진행할 수도 있다.\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
        "                          keras.layers.Dense(10, activation='softmax', name='output')\n",
        "], name='Fashion_MNIST_Model')"
      ],
      "metadata": {
        "id": "NVBt9dxRaHsR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 이름은 한글이어도 상관없으나, 층의 이름은 반드시 영문이어야한다."
      ],
      "metadata": {
        "id": "5QH16_p6dfAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWiNL_tHdZOc",
        "outputId": "6c95bdf7-7c81-4236-a8c2-efa37cfa40fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Fashion_MNIST_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "층이 많아질 경우 위와 같은 방식으로 하기 불편해질 수 있는데, 이럴 경우 `add()` 메서드가 사용되곤 한다."
      ],
      "metadata": {
        "id": "9h2LL5GLdqXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(name='Fashion_MNIST_Model')\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax', name='output'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieXmkYAfdbWf",
        "outputId": "f7db92d9-6f84-47e1-91db-3b85e574adc8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Fashion_MNIST_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 앞서 만든 모델을 훈련해보자."
      ],
      "metadata": {
        "id": "y265UCBXeKPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5QCi0b0d8Hf",
        "outputId": "797eeee5-4f5c-49a2-d192-cea5b667a27f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 6s 3ms/step - loss: 0.5605 - accuracy: 0.8082\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4068 - accuracy: 0.8531\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3726 - accuracy: 0.8648\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3492 - accuracy: 0.8730\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3322 - accuracy: 0.8792\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f694c880650>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "추가된 층이 성능을 향상시켰다. 층의 몇 개가 추가되는 사용법이 동일한 것은 케라스 API의 장점 중 하나이다."
      ],
      "metadata": {
        "id": "mNiR7aiCexw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 렐루 함수"
      ],
      "metadata": {
        "id": "w0EPsujIsHpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "초창기 인공 신경망 은닉층에는 시그모이드 함수가 활성화 함수로써 많이 사용되었다. 하지만 시그모이드는 양극단으로 갈수록 그래프의 기울기가 줄어들기 때문에 올바른 출력을 만드는데 신속하게 대응하지 못한다는 단점을 가진다. \n",
        "\n",
        "$\\phi = {1\\over {1+e^{-z}}}$\n",
        "\n",
        "이러한 문제는 층이 많은 심층 신경망이 등장하면서 더더욱 대두되었고 이에 따라 ReLU 활성화 함수가 대체재로서 제안되었다.\n",
        "\n",
        "렐루 함수는 입력이 양수일 경우 그냥 입력을 통과시키고 음수일 경우 0으로 만든다.\n",
        "\n",
        "렐루 함수는 `max(0, z)`로도 나타낼 수 있다."
      ],
      "metadata": {
        "id": "rHGN2p91sJKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "렐루 함수는 특히 이미지 처리에서 좋은 성능을 내는 것으로 알려져 있다."
      ],
      "metadata": {
        "id": "G8Qygmuls2Nz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "패션 MNIST 데이터는 28 * 28 크기이기 때문에 인공 신경망에 주입하기 위해서 `reshape()` 메서드를 사용해 1차원 배열로 바꿔주었다. 하지만 케라스에서는 이를 위한 Flatten 레이어를 제공한다.\n",
        "\n",
        "사실상 Flatten 층은 입력에 곱해지는 가중치나 절편이 없어 별도의 처리를 하진 않고 신경망 성능에 기여하는 바가 없지만, Flatten 클래스가 입력층과 은닉층 사이에 추가된다는 점 때문에 층이라고 취금한다."
      ],
      "metadata": {
        "id": "kyPS5nQItydM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(name='FMNIST_relu')\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu', name='hidden'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax', name='output'))"
      ],
      "metadata": {
        "id": "vLEruYTjernT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-xI4HADuxP3",
        "outputId": "36199786-7123-436d-bb94-3b15cd8b0541"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"FMNIST_relu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`summary()`에서는 층이 3개처럼 출력되지만 Flatten 클래스는 학습을 수행하는 층이 아니기 때문에 깊이가 3이 아니라 2이다. 위 flatten 층에 파라미터 개수가 0인 것을 통해 더욱 확실히 알 수 있다."
      ],
      "metadata": {
        "id": "7knttcbCu0ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_scaled = X_train / 255.0\n",
        "# train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "\n",
        "train_scaled, val_scaled, y_train, y_val = train_test_split(train_scaled, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "W70nvZMMvjvA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV4Wgd01uyPJ",
        "outputId": "05d50bc6-5bf9-4a1f-9b1d-a8437b618ecd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5343 - accuracy: 0.8126\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3953 - accuracy: 0.8585\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3567 - accuracy: 0.8706\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3359 - accuracy: 0.8797\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3225 - accuracy: 0.8846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f694c6ca7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PReY054VvRxV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}